{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine metadata from sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm = pd.read_csv(\"brainmap/brainmap_metadata_180809.csv\", header=0, index_col=None, encoding=\"cp858\")\n",
    "ns = pd.read_csv(\"neurosynth/neurosynth_180805.csv\", header=0, index_col=None)\n",
    "ac = pd.read_csv(\"ace/ace_180805.csv\", header=0, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = bm.copy()\n",
    "df[\"PMID\"] = pd.to_numeric(df[\"PMID\"], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns[\"id\"] = pd.to_numeric(ns[\"id\"], downcast=\"integer\")\n",
    "ac[\"id\"] = pd.to_numeric(ac[\"id\"], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"SOURCE\"] = \"BrainMap\"\n",
    "df[\"MNI_COORDINATES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load BrainMap coordinates\n",
    "coord = {}\n",
    "for splitter, study in itertools.groupby(open(\"brainmap/coordinates_180803.txt\").readlines(), \n",
    "                                         lambda line: line == \"\\n\"):\n",
    "    if not splitter:\n",
    "        study = list(study)\n",
    "        key = study[0].replace(\"// \", \"\").split(\": \")[0]\n",
    "        if key in list(bm[\"KEY\"]):\n",
    "            try:\n",
    "                pmid = int(bm.loc[bm[\"KEY\"] == key, \"PMID\"])\n",
    "            except:\n",
    "                print(key)\n",
    "            if pmid not in coord.keys():\n",
    "                coord[pmid] = []\n",
    "            for line in study:\n",
    "                if not line.startswith(\"//\"):\n",
    "                    coord[pmid].append(line.replace(\"\\t\", \",\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    pmid = row[\"PMID\"]\n",
    "    if pmid in coord.keys():\n",
    "        df.set_value(i, \"MNI_COORDINATES\", \";\".join(coord[pmid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Neurosynth data \n",
    "for pmid in sorted(list(set(ns[\"id\"]))):\n",
    "    if pmid not in list(df[\"PMID\"]):\n",
    "        rows = ns[ns[\"id\"] == pmid]\n",
    "        row = rows.iloc[0]\n",
    "        dic = {\"BRAINMAP_ID\": [], \"PMID\": [pmid], \"KEY\": [row[\"authors\"].split(\",\")[0] + \", \" + str(row[\"year\"])], \n",
    "               \"1st_AUTHOR\": [row[\"authors\"].split(\",\")[0]], \"AUTHORS\": [row[\"authors\"]], \n",
    "               \"YEAR\": [row[\"year\"]], \"TITLE\": [row[\"title\"]], \"JOURNAL\": [row[\"journal\"]], \n",
    "               \"VOLUME\": [], \"MONTH\": [], \"PAGES\": [], \"BEHAVIORAL_DOMAIN\": [], \"EXPERIMENT\": [], \"DESCRIPTION\": [], \n",
    "               \"ABSTRACT_URL\": [\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids={}&dopt=Abstract\".format(row[\"id\"])], \n",
    "               \"NUM_COORDINATES\": [], \"NUM_SUBJECTS\": [], \"DOI\": [row[\"doi\"]], \"SOURCE\": [\"Neurosynth\"], \"MNI_COORDINATES\": [\";\".join(list(rows[\"mni_coord\"]))]}\n",
    "        new_row = pd.DataFrame.from_dict(dic, orient=\"index\").transpose()\n",
    "        df = df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add ACE data\n",
    "for pmid in sorted(list(set(ac[\"id\"]))):\n",
    "    if pmid not in list(df[\"PMID\"]):\n",
    "        rows = ac[ac[\"id\"] == pmid]\n",
    "        row = rows.iloc[0]\n",
    "        dic = {\"BRAINMAP_ID\": [], \"PMID\": [pmid], \"KEY\": [row[\"authors\"].split(\",\")[0] + \", \" + str(row[\"year\"])], \n",
    "               \"1st_AUTHOR\": [row[\"authors\"].split(\",\")[0]], \"AUTHORS\": [row[\"authors\"]], \n",
    "               \"YEAR\": [row[\"year\"]], \"TITLE\": [row[\"title\"]], \"JOURNAL\": [row[\"journal\"]], \n",
    "               \"VOLUME\": [], \"MONTH\": [], \"PAGES\": [], \"BEHAVIORAL_DOMAIN\": [], \"EXPERIMENT\": [], \"DESCRIPTION\": [], \n",
    "               \"ABSTRACT_URL\": [\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids={}&dopt=Abstract\".format(row[\"id\"])], \n",
    "               \"NUM_COORDINATES\": [], \"NUM_SUBJECTS\": [], \"DOI\": [row[\"doi\"]], \"SOURCE\": [\"ACE\"], \"MNI_COORDINATES\": [\";\".join(list(rows[\"mni_coord\"]))]}\n",
    "        new_row = pd.DataFrame.from_dict(dic, orient='index').transpose()\n",
    "        df = df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18197"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(df[\"PMID\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"PMID\", \"DOI\", \"KEY\", \"SOURCE\", \"AUTHORS\", \"YEAR\", \"MONTH\", \"JOURNAL\", \n",
    "           \"TITLE\", \"PAGES\", \"VOLUME\", \"ABSTRACT_URL\", \"NUM_COORDINATES\", \"MNI_COORDINATES\", \n",
    "           \"BRAINMAP_ID\", \"BEHAVIORAL_DOMAIN\", \"EXPERIMENT\", \"DESCRIPTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"metadata_raw_180811.csv\", index=None, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter by data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"metadata_raw_180811.csv\", index_col=None, header=0, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_avail = [int(file.replace(\".txt\", \"\")) for file in os.listdir(\"../coordinates/0mm\") if not file.startswith(\".\")]\n",
    "texts_avail = [int(file.replace(\".txt\", \"\")) for file in os.listdir(\"../../nlp/corpus\") if not file.startswith(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18155"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"PMID\"].isin(coords_avail)]\n",
    "df = df[df[\"PMID\"].isin(texts_avail)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = [k for k, v in Counter(df[\"PMID\"]).items() if v > 1]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"metadata_filt_180811.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into dev, train, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prop = 0.7\n",
    "val_prop = 0.2\n",
    "test_prop = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set:   12708 (70.00%)\n",
      "Length of validation set:  3631 (20.00%)\n",
      "Length of test set:        1816 (10.00%)\n",
      "Assigned IDs:             18155 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "ids = [int(id) for id in df[\"PMID\"]]\n",
    "train, rest = train_test_split(ids, test_size=val_prop+test_prop, random_state=42)\n",
    "val, test = train_test_split(rest, test_size=test_prop/(val_prop+test_prop), random_state=42)\n",
    "print(\"Length of training set:   {:5d} ({:.2f}%)\".format(len(train), 100*len(train)/len(ids)))\n",
    "print(\"Length of validation set: {:5d} ({:.2f}%)\".format(len(val), 100*len(val)/len(ids)))\n",
    "print(\"Length of test set:       {:5d} ({:.2f}%)\".format(len(test), 100*len(test)/len(ids)))\n",
    "print(\"Assigned IDs:             {:5d} ({:.2f}%)\".format(len(train)+len(val)+len(test), 100*(len(train)+len(val)+len(test))/len(ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"splits/train.txt\", \"w+\") as file:\n",
    "    file.write(\"\\n\".join([str(id) for id in train]))\n",
    "with open(\"splits/validation.txt\", \"w+\") as file:\n",
    "    file.write(\"\\n\".join([str(id) for id in val]))\n",
    "with open(\"splits/test.txt\", \"w+\") as file:\n",
    "    file.write(\"\\n\".join([str(id) for id in test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile document-coordinate matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"metadata_filt_180811.csv\", index_col=None, header=0, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlab = open(\"../labels/harvard-oxford_148struct.csv\", \"r\").readlines()[1:]\n",
    "labels_bilateral = sorted(set([line.split(\",\")[2] for line in inlab]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_label_bilateral(label):\n",
    "    parts_to_replace = [\"_iiv\", \"_v\", \"_vi\", \"_vermis_vi\", \"_crus_i\", \"_vermis_crus_i\", \"_crus_ii\", \"_vermis_crus_ii\", \"_viib\", \"_vermis_viib\", \"_viiia\", \"_vermis_viiia\", \"_viiib\", \"_vermis_viiib\", \"_ix\", \"_vermis_ix\", \"_x\", \"_vermis_x\"]\n",
    "    for part in parts_to_replace:\n",
    "        if label.endswith(part):\n",
    "            label = label.replace(part, \"_cerebellum\")\n",
    "    parts_to_remove = [\"juxtapositional_lobule_cortex_(formerly_\", \")\", \"_(includes_h1_and_h2\"]\n",
    "    for part in parts_to_remove:\n",
    "        label = label.replace(part, \"\")\n",
    "    return label.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_thres_dcm(df, prob, sigma=0, atlas=\"bilateral\", labs=[]): \n",
    "    dcm = {}\n",
    "    for pmid in sorted(list(df[\"PMID\"])):\n",
    "        dcm[pmid] = {}\n",
    "        dcm[pmid][\"PMID\"] = int(pmid)\n",
    "        lines = open(\"../coordinates/{}mm/{}.txt\".format(sigma, int(pmid)), \"r\").readlines()\n",
    "        hits = []\n",
    "        for line in lines:\n",
    "            for struct in line.split(\",\"):\n",
    "                if len(struct.split()) == 2:\n",
    "                    label, p = struct.split()\n",
    "                    if float(p) > prob:\n",
    "                        if atlas == \"unilateral\":\n",
    "                            hits += [gen_label_unilateral(label)]\n",
    "                        elif atlas == \"bilateral\":\n",
    "                            hits += [gen_label_bilateral(label)]\n",
    "        for label in labs:\n",
    "            count = hits.count(label)\n",
    "            if count > 0:\n",
    "                dcm[pmid][label] = 1\n",
    "            else:\n",
    "                dcm[pmid][label] = 0\n",
    "    outfile = \"../coordinates/dcm/dcm_{}mm_thres{}.csv\".format(sigma, str(prob).replace(\".\", \"p\"))\n",
    "    with open(outfile, \"w+\"):\n",
    "        out = pd.DataFrame(dcm).transpose()\n",
    "        out.to_csv(outfile, index=False, quoting=1, columns=[\"PMID\"] + labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in [0, 5]:\n",
    "#     for prob in range(0,100,5):\n",
    "    prob = 0.01\n",
    "    if not os.path.isfile(\"../coordinates/dcm/dcm_{}mm_thres{}.csv\".format(sigma, str(prob).replace(\".\", \"p\"))):\n",
    "        prob_thres_dcm(df, prob, sigma=sigma, atlas=\"bilateral\", labs=labels_bilateral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average probability by structure\n",
    "def prob_mean_dcm(df, sigma=0, atlas=\"bilateral\", labs=[]): \n",
    "    dcm = {}\n",
    "    for pmid in sorted(list(df[\"PMID\"])):\n",
    "        dcm[pmid] = {}\n",
    "        dcm[pmid][\"PMID\"] = int(pmid)\n",
    "        lines = open(\"../coordinates/{}mm/{}.txt\".format(sigma, int(pmid)), \"r\").readlines()\n",
    "        hits = []\n",
    "        for line in lines:\n",
    "            for struct in line.split(\",\"):\n",
    "                if len(struct.split()) == 2:\n",
    "                    label, p = struct.split()\n",
    "                    if atlas == \"unilateral\":\n",
    "                        hits += [(gen_label_unilateral(label), p)]\n",
    "                    elif atlas == \"bilateral\":\n",
    "                        hits += [(gen_label_bilateral(label), p)]\n",
    "        for label in labs:\n",
    "            probs = [float(p) for l, p in hits if l == label]\n",
    "            if len(probs) > 0:\n",
    "                dcm[pmid][label] = 0.01 * sum(probs) / len(probs)\n",
    "            else:\n",
    "                dcm[pmid][label] = 0\n",
    "    outfile = \"../coordinates/dcm/dcm_{}mm_mean.csv\".format(sigma)\n",
    "    with open(outfile, \"w+\"):\n",
    "        out = pd.DataFrame(dcm).transpose()\n",
    "        out.to_csv(outfile, index=False, quoting=1, columns=[\"PMID\"] + labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in [0, 5]:\n",
    "    prob_mean_dcm(df, sigma=sigma, atlas=\"bilateral\", labs=labels_bilateral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count by structure\n",
    "def count_dcm(df, sigma=0, atlas=\"bilateral\", labs=[]): \n",
    "    dcm = {}\n",
    "    for pmid in sorted(list(df[\"PMID\"])):\n",
    "        dcm[pmid] = {}\n",
    "        dcm[pmid][\"PMID\"] = int(pmid)\n",
    "        lines = open(\"../coordinates/{}mm/{}.txt\".format(sigma, int(pmid)), \"r\").readlines()\n",
    "        hits = []\n",
    "        for line in lines:\n",
    "            for struct in line.split(\",\"):\n",
    "                if len(struct.split()) == 2:\n",
    "                    label, p = struct.split()\n",
    "                    if atlas == \"unilateral\":\n",
    "                        hits += [(gen_label_unilateral(label), p)]\n",
    "                    elif atlas == \"bilateral\":\n",
    "                        hits += [(gen_label_bilateral(label), p)]\n",
    "        for label in labs:\n",
    "            probs = [float(p) for l, p in hits if l == label]\n",
    "            dcm[pmid][label] = len(probs)\n",
    "    outfile = \"../coordinates/dcm/dcm_{}mm_count.csv\".format(sigma)\n",
    "    with open(outfile, \"w+\"):\n",
    "        out = pd.DataFrame(dcm).transpose()\n",
    "        out.to_csv(outfile, index=False, quoting=1, columns=[\"PMID\"] + labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in [0, 5]:\n",
    "    count_dcm(df, sigma=sigma, atlas=\"bilateral\", labs=labels_bilateral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Article sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3346"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"SOURCE\"] == \"BrainMap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2133"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"SOURCE\"] == \"ACE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12676"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"SOURCE\"] == \"Neurosynth\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
