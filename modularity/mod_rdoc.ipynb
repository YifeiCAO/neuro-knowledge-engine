{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In a prior notebook, documents were partitioned by assigning them to the domain with the highest Dice similarity of their term and structure occurrences. Here, we'll assess whether the observed modularity of the partitions is greater than expected by chance. Modularity will be measured by the ratio of dispersion between partitions to dispersion within partitions.\n",
    "\n",
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = \"rdoc\" \n",
    "version = 190124 # Document-term matrix version\n",
    "suffix = \"_opsim\" # Suffix for term lists\n",
    "n_iter = 10000 # Iterations for bootstrap and null\n",
    "dx = [0.38, 0.38, 0.38, 0.35, 0.36, 0.36, 0.35] # Nudges for plotted means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain activation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document N=18155, Structure N=114\n"
     ]
    }
   ],
   "source": [
    "act_bin = load_coordinates()\n",
    "print(\"Document N={}, Structure N={}\".format(\n",
    "      act_bin.shape[0], act_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_bin = load_doc_term_matrix(version=version, binarize=True)\n",
    "print(\"Document N={}, Term N={}\".format(\n",
    "      dtm_bin.shape[0], dtm_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain archetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists, circuits = load_framework(framework, suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(list(set(lists[\"TOKEN\"])))\n",
    "structures = sorted(list(set(act_bin.columns)))\n",
    "domains = list(OrderedDict.fromkeys(lists[\"DOMAIN\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archetypes = pd.DataFrame(0.0, index=words+structures, columns=domains)\n",
    "for dom in domains:\n",
    "    for word in lists.loc[lists[\"DOMAIN\"] == dom, \"TOKEN\"]:\n",
    "        archetypes.loc[word, dom] = 1.0\n",
    "    for struct in structures:\n",
    "        archetypes.loc[struct, dom] = circuits.loc[struct, dom]\n",
    "archetypes[archetypes > 0.0] = 1.0\n",
    "print(\"Term & Structure N={}, Domain N={}\".format(\n",
    "      archetypes.shape[0], archetypes.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document structure-term vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids = dtm_bin.index.intersection(act_bin.index)\n",
    "len(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_words = dtm_bin.loc[pmids, words]\n",
    "act_structs = act_bin.loc[pmids, structures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = dtm_words.copy()\n",
    "docs[structures] = act_structs.copy()\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2dom_df = pd.read_csv(\"../partition/data/doc2dom_{}.csv\".format(framework), \n",
    "                         header=None, index_col=0)\n",
    "doc2dom = {int(pmid): int(dom) for pmid, dom in doc2dom_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom2docs = {dom: [] for dom in domains}\n",
    "for doc, dom in doc2dom.iteritems():\n",
    "    dom2docs[domains[dom-1]].append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute domain modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = np.mean(docs).values\n",
    "df_obs = pd.DataFrame(index=domains, columns=pmids)\n",
    "df = pd.DataFrame(index=domains, columns=[\"OBSERVED\"])\n",
    "for dom in domains:\n",
    "    dom_pmids = dom2docs[dom]\n",
    "    dom_vecs = docs.loc[dom_pmids].values\n",
    "    dom_centroid = np.mean(dom_vecs, axis=0)\n",
    "    dist_ext = (dom_vecs - centroid) ** 2\n",
    "    dist_int = (dom_vecs - dom_centroid) ** 2\n",
    "    df_obs.loc[dom, dom_pmids] = np.sum(dist_ext, axis=1) / np.sum(dist_int, axis=1)\n",
    "    df.loc[dom, \"OBSERVED\"] = np.mean(np.sum(dist_ext) / np.sum(dist_int))\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_null = \"data/mod_null_{}_{}iter.csv\".format(framework, n_iter)\n",
    "if not os.path.isfile(file_null):\n",
    "    df_null = np.empty((len(domains), n_iter))\n",
    "    for n in range(n_iter):\n",
    "        null = np.random.choice(range(docs.shape[1]), size=docs.shape[1], replace=False)\n",
    "        centroid = np.mean(docs)[null].values\n",
    "        for i, dom in enumerate(domains):\n",
    "            dom_pmids = dom2docs[dom]\n",
    "            dom_vecs = docs.loc[dom_pmids].values\n",
    "            dom_centroid = np.mean(dom_vecs, axis=0)[null]\n",
    "            n_docs = dom_vecs.shape[0]\n",
    "            dist_ext = (dom_vecs - centroid) ** 2\n",
    "            dist_int = (dom_vecs - dom_centroid) ** 2\n",
    "            df_null[i,n] = np.sum(dist_ext) / np.sum(dist_int)\n",
    "        if n % int(n_iter / 10.0) == 0:\n",
    "            print(\"Processed {} iterations\".format(n))\n",
    "    df_null = pd.DataFrame(df_null, index=domains, columns=range(n_iter))\n",
    "    df_null.to_csv(file_null)\n",
    "else:\n",
    "    df_null = pd.read_csv(file_null, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import multitest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.00001, 0.000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = []\n",
    "for dom in domains:   \n",
    "    dom_null = df_null.loc[dom].values\n",
    "    dom_obs = float(df.loc[dom, \"OBSERVED\"])\n",
    "    p = np.sum(np.greater(dom_null, dom_obs)) / float(n_iter)\n",
    "    pval.append(p)\n",
    "    df.loc[dom, \"P\"] = p\n",
    "df[\"FDR\"] = multitest.multipletests(pval, method=\"fdr_bh\")[1]\n",
    "for dom in domains:\n",
    "    for star, alpha in zip([\"*\", \"**\", \"***\"], alphas):\n",
    "        if df.loc[dom, \"FDR\"] < alpha:\n",
    "            df.loc[dom, \"STARS\"] = star\n",
    "        else:\n",
    "            df.loc[dom, \"STARS\"] = \"\"\n",
    "df = df.loc[domains, [\"OBSERVED\", \"P\", \"FDR\", \"STARS\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = palettes[framework]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_violins(framework, domains, df, df_null, df_obs, palette, \n",
    "             dx=dx, alphas=alphas, interval=0.999)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ontol)",
   "language": "python",
   "name": "ontol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
