{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook will take a data-driven approach to generating word lists for mental functions that are related to brain circuitry. The overall process is as follows:\n",
    "\n",
    "1. Cluster brain structures into circuits by PMI-weighted co-occurrences with mental function terms.\n",
    "2. Identify the mental function terms most highly associated to each circuit over a range of list lengths.\n",
    "3. Select the list length for each circuit that maximizes word-structure classification performance. \n",
    "4. Select the number of circuits that maximizes circuit-function classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain activation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document N=18155, Structure N=114\n"
     ]
    }
   ],
   "source": [
    "act_bin = load_coordinates()\n",
    "print(\"Document N={}, Structure N={}\".format(act_bin.shape[0], act_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms for mental functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5e493b709b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m190325\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdtm_bin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_doc_term_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/Stanford/Research/Projects/Thesis/program/neuro-knowledge-engine/ontology/utilities.py\u001b[0m in \u001b[0;36mload_doc_term_matrix\u001b[0;34m(version, binarize)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_doc_term_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m190124\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/text/dtm_{}.csv.gz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mdtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_mean_thres\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ontol/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[1;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "version = 190325\n",
    "dtm_bin = load_doc_term_matrix(version=version, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = load_lexicon([\"cogneuro\"])\n",
    "lexicon = sorted(list(set(lexicon).intersection(dtm_bin.columns)))\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_bin = dtm_bin[lexicon]\n",
    "print(\"Document N={}, Term N={}\".format(dtm_bin.shape[0], dtm_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = [[int(pmid.strip()) for pmid in open(\"../data/splits/{}.txt\".format(split))] for split in [\"train\", \"validation\"]]\n",
    "print(\"Training N={}, Validation N={}\".format(len(train), len(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link structures to functions\n",
    "\n",
    "Links are computed as PMI-weighted co-occurrences across the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm = np.dot(act_bin.loc[train].transpose(), dtm_bin.loc[train])\n",
    "stm = pd.DataFrame(stm, columns=dtm_bin.columns, index=act_bin.columns)\n",
    "stm = pmi(stm, positive=False)\n",
    "stm = stm.dropna(axis=1, how=\"all\") # Drop terms with no co-occurrences\n",
    "print(\"Structure N={}, Term N={}\".format(stm.shape[0], stm.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terms most strongly linked to the left amygdala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm.loc[\"left_amygdala\"].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structures most strongly linked to *face_identification_task*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stm[\"face_identification_task\"].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the ontology\n",
    "\n",
    "## 1. Cluster brain structures by functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import pointbiserialr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_counts = range(2, 41) # Range over which ROC-AUC becomes asymptotic\n",
    "list_lens = range(5, 26) # Same range as RDoC and the DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    circuit_file = \"circuits/circuits_k{:02d}.csv\".format(k)\n",
    "    if not os.path.isfile(circuit_file):\n",
    "        kmeans = KMeans(n_clusters=k, max_iter=1000, random_state=42)\n",
    "        kmeans.fit(stm)\n",
    "        clust = pd.DataFrame({\"STRUCTURE\": act_bin.columns, \n",
    "                              \"CLUSTER\": [l+1 for l in list(kmeans.labels_)]})\n",
    "        clust = clust.sort_values([\"CLUSTER\", \"STRUCTURE\"])\n",
    "        clust.to_csv(circuit_file, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identify associated terms for mental functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    circuit_file = \"circuits/circuits_k{:02d}.csv\".format(k)\n",
    "    clust = pd.read_csv(circuit_file, index_col=None)\n",
    "    outfile = \"lists/lists_k{:02d}.csv\".format(k)\n",
    "    if not os.path.isfile(outfile):\n",
    "        lists = pd.DataFrame()\n",
    "        for i in range(k):\n",
    "            structures = list(clust.loc[clust[\"CLUSTER\"] == i+1, \"STRUCTURE\"])\n",
    "            centroid = np.mean(act_bin.loc[train, structures], axis=1)\n",
    "            R = pd.Series([pointbiserialr(dtm_bin.loc[train, word], centroid)[0] \n",
    "                           for word in dtm_bin.columns], index=dtm_bin.columns)\n",
    "            R = R[R > 0].sort_values(ascending=False)[:max(list_lens)]\n",
    "            R = pd.DataFrame({\"CLUSTER\": [i+1 for l in range(max(list_lens))], \n",
    "                              \"TOKEN\": R.index, \"R\": R.values})\n",
    "            lists = lists.append(R)\n",
    "        lists.to_csv(outfile, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select number of words per domain\n",
    "\n",
    "Word list lengths were selected by mean ROC-AUC of forward and reverse classifiers for each circuit. The number of circuits will be selected across values of k using the lists of optimized length, this time training classifiers that use all the circuits at that k. All classifiers were optimized over a grid search for regularization strength, penalty, and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = [\"forward\", \"reverse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = {}\n",
    "for d in directions:\n",
    "    fits[d] = {}\n",
    "    for k in circuit_counts:\n",
    "        fits[d][k] = pickle.load(open(\"sherlock/fits/{}_k{:02d}_oplen.p\".format(d, k), \"rb\"), encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select optimal number of domains\n",
    "\n",
    "### Circuit-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {k: {} for k in circuit_counts}\n",
    "for k in circuit_counts:\n",
    "    domains = range(1, k+1)\n",
    "    lists, circuits = load_ontology(k)\n",
    "    function_features = pd.DataFrame(index=dtm_bin.index, columns=domains)\n",
    "    structure_features = pd.DataFrame(index=act_bin.index, columns=domains)\n",
    "    for i in domains:\n",
    "        functions = lists.loc[lists[\"CLUSTER\"] == i, \"TOKEN\"]\n",
    "        function_features[i] = dtm_bin[functions].sum(axis=1)\n",
    "        structures = circuits.loc[circuits[\"CLUSTER\"] == i, \"STRUCTURE\"]\n",
    "        structure_features[i] = act_bin[structures].sum(axis=1)\n",
    "    function_features = pd.DataFrame(doc_mean_thres(function_features), \n",
    "                                     index=dtm_bin.index, columns=domains)\n",
    "    structure_features = pd.DataFrame(binarize(structure_features), \n",
    "                                     index=act_bin.index, columns=domains)\n",
    "    features[k][\"function\"] = function_features\n",
    "    features[k][\"structure\"] = structure_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the receiver operating characteristic curve (ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocauc_scores = compute_eval_scores(roc_auc_score, directions, features, fits, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocauc_boot = compute_eval_boot(roc_auc_score, directions, features, fits, val, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocauc_null = compute_eval_null(roc_auc_score, directions, features, fits, val, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions += [\"mean\"]\n",
    "shapes = [\">\", \"<\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for direction, shape in zip(directions, shapes):\n",
    "    plot_scores(rocauc_scores, direction, rocauc_boot, rocauc_null, \n",
    "                \"rocauc\", shape=shape, ylim=[0.485,0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_k = 7\n",
    "lists, circuits = load_ontology(op_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2name = {}\n",
    "for k in range(op_k):\n",
    "    degrees = term_degree_centrality(k+1, lists, circuits, dtm_bin, train)\n",
    "    name = nounify(degrees.index[0], dtm_bin).upper()\n",
    "    k2name[k+1] = name\n",
    "    print(\"{}: {}\".format(k+1, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export ontology with domain names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [6, 3, 7, 5, 2, 1, 4]\n",
    "names = [k2name[k] for k in order]\n",
    "k2order = {k: order.index(k)+1 for k in range(1,op_k+1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function term lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ORDER\", \"CLUSTER\", \"DOMAIN\", \"TOKEN\", \"R\", \"ROC_AUC\"]\n",
    "lists[\"ORDER\"] = [k2order[k] for k in lists[\"CLUSTER\"]]\n",
    "lists[\"DOMAIN\"] = [k2name[k] for k in lists[\"CLUSTER\"]]\n",
    "lists = lists.sort_values([\"ORDER\", \"R\"], ascending=[True, False])\n",
    "lists = lists[columns]\n",
    "lists.to_csv(\"lists/lists_data-driven.csv\", index=None)\n",
    "lists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"ORDER\", \"CLUSTER\", \"DOMAIN\", \"STRUCTURE\"]\n",
    "circuits[\"ORDER\"] = [k2order[k] for k in circuits[\"CLUSTER\"]]\n",
    "circuits[\"DOMAIN\"] = [k2name[k] for k in circuits[\"CLUSTER\"]]\n",
    "circuits = circuits.sort_values([\"ORDER\", \"STRUCTURE\"])\n",
    "circuits = circuits[columns]\n",
    "circuits.to_csv(\"circuits/clusters_data-driven.csv\", index=None)\n",
    "circuits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_mat = pd.DataFrame(0.0, index=act_bin.columns, columns=names)\n",
    "for name in names:\n",
    "    structures = circuits.loc[circuits[\"DOMAIN\"] == name, \"STRUCTURE\"]\n",
    "    for structure in structures:\n",
    "        circuit_mat.loc[structure, name] = 1.0\n",
    "circuit_mat.to_csv(\"circuits/circuits_data-driven.csv\")\n",
    "circuit_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = load_atlas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purples = make_cmap([(1,1,1), (0.365,0,0.878)])\n",
    "magentas = make_cmap([(1,1,1), (0.620,0,0.686)])\n",
    "yellows = make_cmap([(1,1,1), (0.937,0.749,0)])\n",
    "cmaps = [\"Blues\", magentas, yellows, \"Greens\", \"Reds\", purples, \"Oranges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_plane(circuit_mat, atlas, \"figures/circuits/data-driven\", \n",
    "          suffix=\"_z\", cmaps=cmaps, plane=\"z\", cbar=False, vmin=0.0, vmax=2.0,\n",
    "          verbose=False, print_fig=True, annotate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plane in [\"x\", \"y\"]:\n",
    "    map_plane(circuit_mat, atlas, \"figures/circuits/data-driven\", \n",
    "          suffix=\"_\"+plane, cmaps=cmaps, plane=plane, cbar=False, vmin=0.0, vmax=2.0,\n",
    "          verbose=False, print_fig=False, annotate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ontol)",
   "language": "python",
   "name": "ontol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
