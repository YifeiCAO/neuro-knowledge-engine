{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook will take a data-driven approach to generating word lists for mental functions that are related to brain circuitry. The overall process is as follows:\n",
    "\n",
    "1. Cluster brain structures into circuits by PMI-weighted co-occurrences with mental function terms.\n",
    "2. Identify the mental function terms most highly associated to each circuit over a range of list lengths.\n",
    "3. Select the list length for each circuit that maximizes word-structure classification performance. \n",
    "4. Select the number of circuits that maximizes circuit-function classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import utilities, ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster range to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_counts = range(2, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain activation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document N=18155, Structure N=114\n"
     ]
    }
   ],
   "source": [
    "act_bin = utilities.load_coordinates()\n",
    "print(\"Document N={}, Structure N={}\".format(\n",
    "      act_bin.shape[0], act_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms for mental functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 190325\n",
    "dtm_bin = utilities.load_doc_term_matrix(version=version, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = utilities.load_lexicon([\"cogneuro\"])\n",
    "lexicon = sorted(list(set(lexicon).intersection(dtm_bin.columns)))\n",
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document N=18155, Term N=1683\n"
     ]
    }
   ],
   "source": [
    "dtm_bin = dtm_bin[lexicon]\n",
    "print(\"Document N={}, Term N={}\".format(\n",
    "      dtm_bin.shape[0], dtm_bin.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4831488"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total occurrences of terms in the lexicon\n",
    "dtm = utilities.load_doc_term_matrix(version=version, binarize=False)\n",
    "dtm = dtm[lexicon]\n",
    "np.sum(dtm.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training N=12708, Validation N=3631\n"
     ]
    }
   ],
   "source": [
    "train, val = [[int(pmid.strip()) \n",
    "               for pmid in open(\"../data/splits/{}.txt\".format(split))] \n",
    "                    for split in [\"train\", \"validation\"]]\n",
    "print(\"Training N={}, Validation N={}\".format(len(train), len(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name the domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2terms, k2name = {}, {}\n",
    "for k in circuit_counts:\n",
    "    lists, circuits = ontology.load_ontology(k)\n",
    "    k2terms[k] = {i: list(set(lists.loc[lists[\"CLUSTER\"] == i+1, \"TOKEN\"])) for i in range(k)}\n",
    "    k2name[k] = {i+1: \"\" for i in range(k)}\n",
    "    names, degs = [\"\"]*k, [0]*k\n",
    "    while \"\" in names:\n",
    "        for i in range(k):\n",
    "            degrees = ontology.term_degree_centrality(i+1, lists, circuits, dtm_bin, train)\n",
    "            degrees = degrees.loc[k2terms[k][i]].sort_values(ascending=False)\n",
    "            name = degrees.index[0].upper()\n",
    "            if name not in names:\n",
    "                names[i] = name\n",
    "                degs[i] = max(degrees)\n",
    "                k2name[k][i+1] = name\n",
    "            elif name in names:\n",
    "                name_idx = names.index(name)\n",
    "                if degs[name_idx] > degs[i]:\n",
    "                    k2terms[k][i] = [term for term in k2terms[k][i] if term != name.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2order = {2: [1,2],\n",
    "           3: [1,2,3],\n",
    "           4: [4,3,1,2],\n",
    "           5: [4,1,3,2,5],\n",
    "           6: [3,6,5,4,2,1],\n",
    "           7: [6,3,7,2,5,4,1],\n",
    "           8: [4,8,5,1,3,2,7,6],\n",
    "           9: [5,9,1,2,8,3,6,7,4],\n",
    "           10: [5,1,10,3,9,6,8,2,7,4],\n",
    "           11: [1,11,8,9,10,5,2,3,4,6,7],\n",
    "           12: [4,6,7,9,3,1,10,11,12,2,8,5],\n",
    "           13: [5,10,7,1,9,13,2,6,11,3,4,12,8],\n",
    "           14: [11,8,6,7,10,13,12,3,1,9,4,14,5,2],\n",
    "           15: [2,13,14,12,6,7,15,5,4,8,10,11,3,1,9],\n",
    "           16: [1,2,6,10,7,15,16,9,13,4,3,12,11,5,14,8],\n",
    "           17: [7,8,10,13,4,17,5,15,6,11,3,2,14,1,9,12,16],\n",
    "           18: [4,10,14,15,5,1,9,11,6,13,17,2,8,12,3,16,7,18],\n",
    "           19: [1,10,16,11,14,5,6,12,13,9,18,3,7,4,2,17,19,15,8],\n",
    "           20: [3,5,13,12,18,20,7,15,10,17,6,1,4,8,11,19,16,9,2,14],\n",
    "           21: [3,6,12,17,9,18,20,5,11,15,7,16,2,21,13,19,1,4,10,8,14],\n",
    "           22: [3,13,20,22,6,14,8,11,9,12,17,1,16,5,7,18,2,19,10,4,21,15],\n",
    "           23: [1,8,10,9,14,15,20,19,21,4,23,12,17,18,11,3,2,5,16,6,13,7,22],\n",
    "           24: [9,15,17,18,21,4,22,23,7,19,10,12,16,14,5,11,2,8,13,6,20,3,1,24],\n",
    "           25: [3,13,20,22,23,6,24,8,11,9,12,17,1,16,18,5,2,7,25,19,10,4,21,14,15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2name_ordered = {k: [k2name[k][i] for i in k2order[k]] for k in circuit_counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: ['Arousal', 'Manipulation'],\n",
       " 3: ['Arousal', 'Manipulation', 'Language'],\n",
       " 4: ['Memory', 'Reaction Time', 'Vision', 'Hearing'],\n",
       " 5: ['Memory', 'Reaction Time', 'Manipulation', 'Vision', 'Language'],\n",
       " 6: ['Memory',\n",
       "  'Reward',\n",
       "  'Reaction Time',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Language'],\n",
       " 7: ['Emotion',\n",
       "  'Anticipation',\n",
       "  'Cognitive Process',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Word'],\n",
       " 8: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reaction Time',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 9: ['Episodic Memory',\n",
       "  'Reward',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Manipulation',\n",
       "  'Memory',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 10: ['Memory',\n",
       "  'Reward',\n",
       "  'Arousal',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 11: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Decision Making',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Meaning'],\n",
       " 12: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Pain',\n",
       "  'Cognitive Process',\n",
       "  'Execution',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 13: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Arousal',\n",
       "  'Cognitive Process',\n",
       "  'Manipulation',\n",
       "  'Retrieval',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Speech',\n",
       "  'Language'],\n",
       " 14: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Arousal',\n",
       "  'Salience',\n",
       "  'Cognitive Process',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Speech',\n",
       "  'Language'],\n",
       " 15: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Retrieval',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Cognitive Process',\n",
       "  'Monitoring',\n",
       "  'Representation',\n",
       "  'Working Memory',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language'],\n",
       " 16: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Emotion',\n",
       "  'Recognition Memory',\n",
       "  'Reward',\n",
       "  'Reward Processing',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Cognitive Control',\n",
       "  'Preparation',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Word',\n",
       "  'Meaning'],\n",
       " 17: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Retrieval',\n",
       "  'Recall',\n",
       "  'Recognition',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Arousal',\n",
       "  'Cognitive Process',\n",
       "  'Preparation',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Speech',\n",
       "  'Language',\n",
       "  'Word'],\n",
       " 18: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Retrieval',\n",
       "  'Recognition',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Reaction Time',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Speech',\n",
       "  'Language',\n",
       "  'Language Processing'],\n",
       " 19: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Recognition',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Anticipation',\n",
       "  'Retrieval',\n",
       "  'Arousal',\n",
       "  'Pain',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Listening',\n",
       "  'Speech',\n",
       "  'Language',\n",
       "  'Word'],\n",
       " 20: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Retrieval',\n",
       "  'Recognition',\n",
       "  'Familiarity',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Cognitive Process',\n",
       "  'Cognitive Control',\n",
       "  'Execution',\n",
       "  'Manipulation',\n",
       "  'Hand',\n",
       "  'Thought',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Word'],\n",
       " 21: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Retrieval',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Reward Processing',\n",
       "  'Anticipation',\n",
       "  'Salience',\n",
       "  'Arousal',\n",
       "  'Reaction Time',\n",
       "  'Meaning',\n",
       "  'Cognitive',\n",
       "  'Manipulation',\n",
       "  'Execution',\n",
       "  'Motor Control',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Speech',\n",
       "  'Language',\n",
       "  'Word'],\n",
       " 22: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Retrieval',\n",
       "  'Recognition',\n",
       "  'Encoding',\n",
       "  'Feedback',\n",
       "  'Fear',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Reward Processing',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Cognitive Process',\n",
       "  'Execution',\n",
       "  'Cognitive Control',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Speech',\n",
       "  'Language',\n",
       "  'Language Processing',\n",
       "  'Word'],\n",
       " 23: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Recognition',\n",
       "  'Familiarity',\n",
       "  'Remembering',\n",
       "  'Encoding',\n",
       "  'Retrieval',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Decision Making',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Salience',\n",
       "  'Cognitive Process',\n",
       "  'Execution',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Listening',\n",
       "  'Speech',\n",
       "  'Language',\n",
       "  'Word',\n",
       "  'Meaning'],\n",
       " 24: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Retrieval',\n",
       "  'Encoding',\n",
       "  'Recognition',\n",
       "  'Feedback',\n",
       "  'Fear',\n",
       "  'Emotion',\n",
       "  'Mood',\n",
       "  'Reward',\n",
       "  'Reward Processing',\n",
       "  'Decision Making',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Reaction Time',\n",
       "  'Execution',\n",
       "  'Manipulation',\n",
       "  'Perception',\n",
       "  'Vision',\n",
       "  'Hearing',\n",
       "  'Language',\n",
       "  'Word',\n",
       "  'Semantic Processing'],\n",
       " 25: ['Memory',\n",
       "  'Episodic Memory',\n",
       "  'Recall',\n",
       "  'Retrieval',\n",
       "  'Remembering',\n",
       "  'Recognition',\n",
       "  'Encoding',\n",
       "  'Feedback',\n",
       "  'Fear',\n",
       "  'Emotion',\n",
       "  'Reward',\n",
       "  'Reward Processing',\n",
       "  'Anticipation',\n",
       "  'Arousal',\n",
       "  'Cognitive Process',\n",
       "  'Manipulation',\n",
       "  'Vision',\n",
       "  'Execution',\n",
       "  'Social Cognition',\n",
       "  'Hearing',\n",
       "  'Speech',\n",
       "  'Language',\n",
       "  'Language Processing',\n",
       "  'Word',\n",
       "  'Meaning']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2name_titles = {}\n",
    "for k in circuit_counts:\n",
    "    k2name_titles[k] = [dom.replace(\"_\", \" \").title() for dom in k2name_ordered[k]]\n",
    "k2name_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the term lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {\"red\": \"#CE7D69\", \"orange\": \"#BA7E39\", \"yellow\": \"#CEBE6D\", \"chartreuse\": \"#AEC87C\", \"green\": \"#77B58A\", \n",
    "     \"blue\": \"#7597D0\", \"magenta\": \"#B07EB6\", \"purple\": \"#7D74A3\", \"brown\": \"#846B43\", \"pink\": \"#CF7593\",\n",
    "     \"slate\": \"#6F8099\", \"crimson\": \"#8C4058\", \"gold\": \"#D8AE54\", \"teal\": \"#5AA8A7\", \"indigo\": \"#3A3C7C\", \n",
    "     \"lobster\": \"#FF7B5B\", \"olive\": \"#72662A\", \"lime\": \"#91E580\", \"sky\": \"#BCD5FF\", \"fuschia\": \"#E291DD\",\n",
    "     \"violet\": \"#8B75EA\", \"tan\": \"#E0BD84\", \"berry\": \"#D64F7C\", \"mint\": \"#A4EACA\", \"sun\": \"#F4FF6B\"}\n",
    "\n",
    "palettes = {\"data-driven\": [c[\"blue\"], c[\"magenta\"], c[\"yellow\"], c[\"green\"], c[\"red\"], \n",
    "                            c[\"purple\"], c[\"chartreuse\"], c[\"orange\"], c[\"pink\"], c[\"brown\"], \n",
    "                            c[\"slate\"], c[\"crimson\"], c[\"gold\"], c[\"teal\"], c[\"indigo\"],\n",
    "                            c[\"lobster\"], c[\"olive\"], c[\"lime\"], c[\"sky\"], c[\"fuschia\"],\n",
    "                            c[\"violet\"], c[\"tan\"], c[\"berry\"], c[\"mint\"], c[\"sun\"]],\n",
    "            \"rdoc\": [c[\"blue\"], c[\"red\"], c[\"green\"], c[\"purple\"], c[\"yellow\"], c[\"orange\"]],\n",
    "            \"dsm\": [c[\"purple\"], c[\"chartreuse\"], c[\"orange\"], c[\"blue\"], c[\"red\"], c[\"magenta\"], c[\"yellow\"], c[\"green\"], c[\"brown\"]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordclouds(k, domains, lists, dtm, framework=\"data-driven\"):\n",
    "\n",
    "    from wordcloud import WordCloud\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for i, dom in enumerate(domains):\n",
    "        def color_func(word, font_size, position, orientation, \n",
    "                       random_state=None, idx=0, **kwargs):\n",
    "            return palettes[framework][i]\n",
    "\n",
    "        tkns = lists.loc[lists[\"DOMAIN\"] == dom, \"TOKEN\"]\n",
    "        freq = dtm[tkns].sum().values\n",
    "        tkns = [t.replace(\"_\", \" \") for t in tkns]\n",
    "\n",
    "        cloud = WordCloud(background_color=\"rgba(255, 255, 255, 0)\", mode=\"RGB\", \n",
    "                          max_font_size=100, prefer_horizontal=1, scale=20, margin=3,\n",
    "                          width=550, height=850, font_path=utilities.arial, \n",
    "                          random_state=42).generate_from_frequencies(zip(tkns, freq))\n",
    "\n",
    "        fig = plt.figure(1, figsize=(2,10))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(cloud.recolor(color_func=color_func, random_state=42))\n",
    "        file_name = \"figures/lists/kvals/k{:02d}_wordcloud_{}.png\".format(k, dom)\n",
    "        plt.savefig(file_name, \n",
    "                    dpi=800, bbox_inches=\"tight\")\n",
    "        utilities.transparent_background(file_name)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    lists = pd.read_csv(\"lists/lists_k{:02d}_oplen.csv\".format(k), index_col=None, header=0)\n",
    "    lists[\"DOMAIN\"] = [k2name[k][i] for i in lists[\"CLUSTER\"]]\n",
    "    lists_ordered = pd.DataFrame()\n",
    "    for name in k2name_ordered[k]:\n",
    "        lists_ordered = lists_ordered.append(lists.loc[lists[\"DOMAIN\"] == name])\n",
    "    plot_wordclouds(k, k2name_ordered[k], lists_ordered, dtm_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = utilities.load_atlas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "purples = utilities.make_cmap([(1,1,1), (0.365,0,0.878)])\n",
    "chartreuses = utilities.make_cmap([(1,1,1), (0.345,0.769,0)])\n",
    "magentas = utilities.make_cmap([(1,1,1), (0.620,0,0.686)])\n",
    "yellows = utilities.make_cmap([(1,1,1), (0.937,0.749,0)])\n",
    "browns = utilities.make_cmap([(1,1,1), (0.82,0.502,0)])\n",
    "pinks = utilities.make_cmap([(1,1,1), (0.788,0,0.604)])\n",
    "cmaps = [\"Blues\", magentas, yellows, \"Greens\", \"Reds\", purples, chartreuses, \"Oranges\", pinks, browns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ehbeam/.local/lib/python3.6/site-packages/nilearn/plotting/find_cuts.py:285: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  data[slices] *= 1.e-3\n"
     ]
    }
   ],
   "source": [
    "for k in range(2, len(cmaps)):\n",
    "    circuits = pd.read_csv(\"circuits/circuits_k{:02d}.csv\".format(k), index_col=None, header=0)\n",
    "    circuits[\"DOMAIN\"] = [k2name[k][i] for i in circuits[\"CLUSTER\"]]\n",
    "    circuit_mat = pd.DataFrame(0.0, index=act_bin.columns, columns=k2name_ordered[k])\n",
    "    for name in k2name_ordered[k]:\n",
    "        structures = circuits.loc[circuits[\"DOMAIN\"] == name, \"STRUCTURE\"]\n",
    "        for structure in structures:\n",
    "            circuit_mat.loc[structure, name] = 1.0\n",
    "    utilities.map_plane(circuit_mat, atlas, \"figures/circuits/kvals/k{:02d}\".format(k), \n",
    "                        suffix=\"_z\", cmaps=cmaps, plane=\"z\", cbar=False, vmin=0.0, vmax=2.0,\n",
    "                        verbose=False, print_fig=False, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the results\n",
    "\n",
    "## File structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    path = \"../../nke-viewer/data/k{:02d}\".format(k)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3d_object                 318\n",
       "abductive_reasoning        11\n",
       "abstract_analogy            6\n",
       "abstract_concrete_task      8\n",
       "abstract_knowledge         57\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = dtm.sum()\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    lists = pd.read_csv(\"lists/lists_k{:02d}_oplen.csv\".format(k), index_col=None, header=0)\n",
    "    lists[\"DOMAIN\"] = [k2name[k][i] for i in lists[\"CLUSTER\"]]\n",
    "    lists[\"CLUSTER\"] = [k2name_ordered[k].index(dom) + 1 for dom in lists[\"DOMAIN\"]]\n",
    "    lists[\"FREQUENCY\"] = [freq.loc[term] for term in lists[\"TOKEN\"]]\n",
    "    lists_ordered = pd.DataFrame()\n",
    "    for name in k2name_ordered[k]:\n",
    "        lists_ordered = lists_ordered.append(lists.loc[lists[\"DOMAIN\"] == name])\n",
    "    lists = lists.sort_values([\"CLUSTER\", \"R\"], ascending=[True, False])\n",
    "    file = \"../../nke-viewer/data/k{:02d}/words_k{:02d}.csv\".format(k, k)\n",
    "    lists.to_csv(file, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atlas_2mm():\n",
    "\n",
    "    import numpy as np\n",
    "    from nilearn import image\n",
    "\n",
    "    cer = \"../data/brain/atlases/Cerebellum-MNIfnirt-maxprob-thr25-2mm.nii.gz\"\n",
    "    cor = \"../data/brain/atlases/HarvardOxford-cort-maxprob-thr25-2mm.nii.gz\"\n",
    "    sub = \"../data/brain/atlases/HarvardOxford-sub-maxprob-thr25-2mm.nii.gz\"\n",
    "\n",
    "    sub_del_dic = {1:0, 2:0, 3:0, 12:0, 13:0, 14:0}\n",
    "    sub_lab_dic_L = {4:1, 5:2, 6:3, 7:4, 9:5, 10:6, 11:7, 8:8}\n",
    "    sub_lab_dic_R = {15:1, 16:2, 17:3, 18:4, 19:5, 20:6, 21:7, 7:8}\n",
    "\n",
    "    sub_mat_L = image.load_img(sub).get_data()[46:,:,:]\n",
    "    sub_mat_R = image.load_img(sub).get_data()[:46,:,:]\n",
    "\n",
    "    for old, new in sub_del_dic.items():\n",
    "        sub_mat_L[sub_mat_L == old] = new\n",
    "    for old, new in sub_lab_dic_L.items():\n",
    "        sub_mat_L[sub_mat_L == old] = new\n",
    "    sub_mat_L = sub_mat_L + 48\n",
    "    sub_mat_L[sub_mat_L == 48] = 0\n",
    "\n",
    "    for old, new in sub_del_dic.items():\n",
    "        sub_mat_R[sub_mat_R == old] = new\n",
    "    for old, new in sub_lab_dic_R.items():\n",
    "        sub_mat_R[sub_mat_R == old] = new\n",
    "    sub_mat_R = sub_mat_R + 48\n",
    "    sub_mat_R[sub_mat_R == 48] = 0\n",
    "\n",
    "    cor_mat_L = image.load_img(cor).get_data()[46:,:,:]\n",
    "    cor_mat_R = image.load_img(cor).get_data()[:46,:,:]\n",
    "\n",
    "    mat_L = np.add(sub_mat_L, cor_mat_L)\n",
    "    mat_L[mat_L > 56] = 0\n",
    "    mat_R = np.add(sub_mat_R, cor_mat_R)\n",
    "    mat_R[mat_R > 56] = 0\n",
    "\n",
    "    mat_R = mat_R + 57\n",
    "    mat_R[mat_R > 113] = 0\n",
    "    mat_R[mat_R < 58] = 0\n",
    "\n",
    "    cer_mat_L = image.load_img(cer).get_data()[46:,:,:]\n",
    "    cer_mat_R = image.load_img(cer).get_data()[:46,:,:]\n",
    "    cer_mat_L[cer_mat_L > 0] = 57\n",
    "    cer_mat_R[cer_mat_R > 0] = 114\n",
    "\n",
    "    mat_L = np.add(mat_L, cer_mat_L)\n",
    "    mat_L[mat_L > 57] = 0\n",
    "    mat_R = np.add(mat_R, cer_mat_R)\n",
    "    mat_R[mat_R > 114] = 0\n",
    "\n",
    "    mat = np.concatenate((mat_R, mat_L), axis=0)\n",
    "    atlas_image = image.new_img_like(sub, mat)\n",
    "\n",
    "    return atlas_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_2mm = load_atlas_2mm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in circuit_counts:\n",
    "    circuits = pd.read_csv(\"circuits/circuits_k{:02d}.csv\".format(k), index_col=None, header=0)\n",
    "    circuits[\"DOMAIN\"] = [k2name[k][i] for i in circuits[\"CLUSTER\"]]\n",
    "    columns = [\"dom{:02d}\".format(i) for i in range(1, k+1)]\n",
    "    circuit_mat = pd.DataFrame(0.0, index=act_bin.columns, columns=columns)\n",
    "    for n, name in enumerate(k2name_ordered[k]):\n",
    "        structures = circuits.loc[circuits[\"DOMAIN\"] == name, \"STRUCTURE\"]\n",
    "        for structure in structures:\n",
    "            circuit_mat.loc[structure, \"dom{:02d}\".format(n+1)] = 1.0 + np.random.uniform()\n",
    "    \n",
    "    for f, feature in enumerate(circuit_mat.columns):\n",
    "        \n",
    "        stat_map = image.copy_img(atlas_2mm).get_data()\n",
    "        data = circuit_mat[feature]\n",
    "        for i, value in enumerate(data):\n",
    "            stat_map[stat_map == i+1] = value\n",
    "        stat_img = image.new_img_like(atlas_2mm, stat_map)\n",
    "        \n",
    "        img_file = \"../../nke-viewer/data/k{:02d}/circuit_k{:02d}_{}.nii.gz\".format(k, k, feature)\n",
    "        stat_img.to_filename(img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ontol)",
   "language": "python",
   "name": "ontol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
